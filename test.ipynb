{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieval agumented generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "from llama_index.core.service_context import ServiceContext\n",
    "# from llama_index.llms import OpenAI\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.graph_stores.nebula import NebulaGraphStore\n",
    "from llama_index.core.llms import LLM\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']= os.getenv('OPEN_API_KEY')\n",
    "documents= SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 69/69 [00:00<00:00, 165.69it/s]\n",
      "Generating embeddings: 100%|██████████| 99/99 [00:02<00:00, 46.08it/s]\n"
     ]
    }
   ],
   "source": [
    "index= VectorStoreIndex.from_documents(documents, show_progress=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x105d770d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engin= index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.indices.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.data_structs import Node\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "# Set similarity_top_k=4 to retrieve 4 similar source from where it get the answere \n",
    "retriever = VectorIndexRetriever(index= index, similarity_top_k=4)\n",
    "#Set the similartiy to specfic threshold\n",
    "nodes = [\n",
    "    NodeWithScore(node=Node(text=\"text1\"), score=0.7),\n",
    "    NodeWithScore(node=Node(text=\"text2\"), score=0.8),\n",
    "]\n",
    "postprocessor= SimilarityPostprocessor(similarity_cutoff= 0.80)\n",
    "query_engin= RetrieverQueryEngine(retriever=retriever, node_postprocessors= [postprocessor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: Attention is the process that enables us to select\n",
      "important information for further processing while inhibiting other\n",
      "information. It helps us focus on specific stimuli in our environment,\n",
      "allowing us to navigate through the overwhelming amount of information\n",
      "we encounter. By choosing what to pay attention to, we can effectively\n",
      "carry out tasks and respond to relevant stimuli.\n",
      "______________________________________________________________________\n",
      "Source Node 1/4\n",
      "Node ID: 009d0bed-88ec-4f6b-890a-42cb5c5a07f7\n",
      "Similarity: 0.8217520449932787\n",
      "Text: 104CHAPTER 3 Attentionwe manage to keep from being overloaded\n",
      "and thus rendered incapable of action? How dowe, moment to moment,\n",
      "choose the information that is meaningful and avoid distraction\n",
      "byirrelevant material? One solution is to focus on some particular\n",
      "piece of information (such asthe sound of your own name or a color of\n",
      "interest) and to ...\n",
      "______________________________________________________________________\n",
      "Source Node 2/4\n",
      "Node ID: 59517c8a-bea3-4e6d-8a1a-4876bd05f05d\n",
      "Similarity: 0.8144328950929791\n",
      "Text: 103C H A P T E R3Attention1.The Nature and Roles of\n",
      "Attention1.1.Failures of Selection1.1.1.Failures of Selection in\n",
      "Space1.1.2.Failures of Selection in Time1.1.3.Sources of\n",
      "LimitationDEBATE:Cars and Conversation1.1.4.Problems in\n",
      "Interpretation1.1.5.When the Brain Fails1.2.Successes of\n",
      "Selection1.2.1.Endogenous and ExogenousEffects in Space1.2.2...\n",
      "______________________________________________________________________\n",
      "Source Node 3/4\n",
      "Node ID: 70698caa-8095-45dc-82ba-360ca52af188\n",
      "Similarity: 0.809690217354773\n",
      "Text: Revisit and Reflect1.What is attention, and how does it operate\n",
      "during cognition?Attention is the process whereby we can select from\n",
      "among the many competingstimuli present in our environment,\n",
      "facilitating processing of some while inhibit-ing processing of\n",
      "others. This selection can be driven endogenously by our goals(e.g.,\n",
      "to find a particular ...\n",
      "______________________________________________________________________\n",
      "Source Node 4/4\n",
      "Node ID: ce052f49-9693-4059-988a-e958f40eb163\n",
      "Similarity: 0.8093049286214947\n",
      "Text: 108CHAPTER 3 Attention superimposed video sequences. In one, two\n",
      "people were playing a hand game inwhich one player tries to slap the\n",
      "opponent’s hand; in the other, three men werethrowing a basketball and\n",
      "moving about (Figure 3–2). When participants were in-structed to track\n",
      "one of the two games, they were successful; but keeping track ofboth\n",
      "ga...\n"
     ]
    }
   ],
   "source": [
    "resopnse= query_engin.query(\"What is attention is all you need?\")\n",
    "# Adding show_source= Ture to give from where it get the answer and with how much silimarty\n",
    "pprint_response(resopnse, show_source= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are a type of mechanism integrated into architectures to extract hierarchical features from data. They typically involve self-attention mechanisms and are used to improve the learning process for positive target instances while reducing the rate of missed detections.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "# check if storage already exists\n",
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "\n",
    "# either way we can now query the index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What are transformers?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
